---
slug: deploying-project-using-elastic-beanstalk
title: "Elastic Beanstalk 환경 구성 및 프로젝트 배포"
description: "개인 프로젝트 Asker 백엔드 서버를 AWS에 배포하는 과정을 기록"
author: oxahex
createdAt: 2024-03-14
tags: ["aws"]
---


개인 프로젝트로 개발한 Asker 백엔드 서버를 배포해보고 싶었다. 내가 만든 프로젝트를 다른 사람, 또는 클라이언트 서버에서 접근하려면 프로젝트를 배포해야 한다. 배포를 하는 방법은 여러가지가 있지만 우선 빠르게 배포를 해보고, 이후에 내가 원하는대로 추가적인 설정을 하면서 공부해보고 싶었다.

Asker는 익명으로 타인에게 질문을 보내고, 답변을 받을 수 있는 일종의 SNS 서비스로, 답변은 로그인 유저만 받을 수 있고, 질문은 로그인/비로그인 유저 모두 익명으로 가능하다. 받은 질문은 로그인 유저 개인만 확인할 수 있고, 질문 목록에서 답변할 질문을 선택해 답변을 작성하면 개인 페이지에 공개된다. 로그인 유저가 답변을 생성하면 질문과 답변은 공개되고, 이를 다른 SNS에 공유할 수 있다.

기능을 최소화해 빠르게 개발하는 것이 목적이었다. 따라서 주요 기능은 다음과 같다.
- Email, OAuth 회원가입/로그인
- 질문/답변 관련 CRUD
- 공개된 질문과 답변 키워드 검색

로컬에서 개발할 때는 Redis, ElasticSearch, MySQL 서버를 Docker Compose로 구동해 개발했다.

- Redis: 인증/인가 시 필요한 데이터를 일시 저장하거나 캐시를 활용해 응답 속도를 높이기 위해 사용
- ElasticSearch: 키워드 기반 검색 기능을 위해 사용
- MySQL: 서비스의 주된 데이터를 저장하기 위해 사용

생각해볼 수 있는 가장 단순한 방법은 서버 애플리케이션까지 Docker Image로 빌드하고, 이를 GCP나 AWS의 클라우드 컴퓨팅 리소스에 업로드하는 것이지만 실제로 서비스를 운영한다면 이런 방식은 사용하지 않을 것이다. 개인 프로젝트에서는 사실 이렇게 하나의 EC2 인스턴스에 캐시 서버, 검색 서버, DB 서버, 애플리케이션 서버를 전부 구동시켜도 동작하는 데는 문제가 없을 것이다. EC2의 용량만 괜찮다면.

하나의 EC2 서버에 모든 서버를 밀어 넣고 구동 시켰을 때는 우선 서버 하나의 문제가 다른 서버에 영향을 주게 된다는 것이 가장 큰 문제라는 생각이 든다. 또 서버 애플리케이션의 트래픽이 증가해서 여러 대의 EC2를 추가로 사용해야 하는 경우에는 캐시, 검색, DB 서버는 애플리케이션 서버 외부에 위치시켜 애플리케이션 서버만 스케일 업을 할 수 있도록 구성하는 것이 더 나은 선택이라는 생각도 든다.

사실 이 모든 문제는 개인 프로젝트이고, 애플리케이션 서버 트래픽이 증가하지 않아 여러 대의 애플리케이션 서버를 두지 않아도 되는 상황에서는 고려할 문제는 아니긴 하다. 하지만 AWS에서 지원하는 기능을 사용해보고 싶었다.

- Redis - AWS Elastic Cache
- MySQL - AWS RDS
- ElasticSearch - GCP 구성

그래서 Redis와 MySQL은 AWS의 자원을 사용하고, ElasticSearch는 GCP에서 따로 구성한 다음 애플리케이션 서버에 연결하는 방식으로 시도해보기로 했다. ElasticSearch를 GCP에 따로 구성하려는 이유는 AWS 과금 문제도 있지만, ElasticSearch 클러스터를 내가 원하는대로 구성해보고 싶었기 때문이다. AWS EC2에 ELK 스택을 전부 구성하려면 AWS에서 제공하는 프리티어 자원으로는 부족했다.

ElasticSearch를 구성하는데 시간이 걸릴 것 같아 검색 기능을 제외한 나머지 부분을 먼저 배포해보기로 했다.


## Application Server

### Elastic Beanstalk
서버 애플리케이션 배포는 AWS Elastic Beanstalk을 이용하기로 했다. 가장 쉽게 배포할 수 있는 방법이기도 하고, 환경을 구성하는 것 자체는 과금이 되지 않기 때문이다. 또, AWS에 대해 잘 아는 것이 아니기 때문에 우선 가장 쉽게 배포할 수 있는 방식을 선택하고, 그 이후에 이러한 배포 과정이 어떻게 이루어지는지 추가적으로 공부하는 것이 조금 더 나와 잘 맞는 방식이라는 생각이 들었다.

내가 원하는 애플리케이션 서버 배포 플로우는 Github main 브랜치에 코드가 병합되면 Github Action을 통해 Elastic Beanstalk를 구동시키는 것이다.

Elastic Beanstalk 환경을 먼저 구성했다. 인스턴스는 t2.micro 하나로 우선 두고, 배포 시에는 신규 t2.micro 인스턴스에 새 버전을 올리고, 문제가 없다면 기존의 인스턴스를 종료하도록 구성했다.

이 작업을 위해서 2개의 역할을 생성했다.

#### aws-elasticbeanstalk-service-role
  - AWSElasticBeanstalkEnhancedHealth: Health Monitoring 시스템에 대한 AWS EB 서비스 정책
  - AWSElasticBeanstalkService: AWS 사용자를 대신해 리소스(e.g. AutoScaling, EC2, S3, CloudFormation, ELB 등)를 생성하고 관리할 수 있는 권한을 부여

#### aws-elasticbeanstalk-ec2-role
  - AWSElasticBeanstalkMulticontainerDocker: Amazon EC2 Container 서비스를 사용해 컨테이너 배포 태스크를 관리할 수 있도록 멀티 컨테이너 Docker 환경의 인스턴스에 액세스
  - AWSElasticBeanstalkWebTier: 웹 서버 환경의 인스턴스의 로그 파일을 S3에 업로드
  - AWSElasticBeanstalkWorkerTier: 작업자 환경의 인스턴스의 로그 파일을 S3d에 업로드, Amazon SQS를 사용해 애플리케이션의 작업 대기열을 모니터링, Amazon DynamoDB, CloudWatch에 지표 게시


### Github Action
그 다음으로는 Github Action을 통해 main 브랜치에 코드가 병합되면 이를 트리거로 Elastic Beanstalk에 새 버전의 빌드 파일을 업로드하도록 설정했다. Github는 AWS 서비스가 아니기 때문에 추가적인 권한이 필요했다.

asker-github-action이라는 이름의 사용자를 생성하고 AdministratorAccess-AWSElasticBeanstalk 권한을 할당했다. Access Key와 Secret은 리포지토리에 AWS_EB_ACCESS_KEY, AWS_EB_ACCESS_SECRET이라는 이름으로 저장해두었다.

Github Action으로 프로젝트를 빌드하고, 이를 EB에 업로드한 이후 EB는 이 파일을 이용해 서버를 띄운다. 따라서 인스턴스가 시작될 때 어떻게 실행할 것인지를 명시해두어야 한다.

가장 먼저 Procfile을 작성했다. [Procfile을 사용한 애플리케이션 프로세스 구성 - AWS Elastic Beanstalk](https://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/java-se-procfile.html)

공식 문서에 따르면 Procfile을 작성할 때는 애플리케이션의 기본 jar 파일을 실행하는 명령 이름은 web이고, Procfile에 첫 번째로 나열해야 한다. 따라서 다음과 같이 명시했다.

```text
web: appstart
```

그러면 appstart라는 명령을 수행하게 된다. 정확히는 `/sbin/appstart`라는 명령을 수행하게 된다. `/bin` 디렉토리와 마찬가지로 명령어를 저장하고 있지만 다른 점은 root 권한이 필요한 명령어가 이 디렉토리에 명시된다. 따라서 `/sbin/appstart` 명령어를 수행했을 때 어떤 작업을 할 것인지 명시해 주어야 한다. EC2 안에 따로 생성해 주어도 동작하지만 EB를 사용하는 이유 중 하나였던 자동 배포 환경에서는 새로운 버전이 업데이트 되면 새 버전이 동작하는 인스턴스가 구동되고, 기존 인스턴스는 종료된다. 따라서 EC2 내부에 이 명령어를 정의하는 것은 별 의미가 없다. 새 인스턴스가 뜰 때마다 명령어를 갱신해주어야 하기 때문에 프로젝트 내부에 명령을 수행하도록 파일을 작성해주는 것이 나은 방법이다.

`.ebextensions` 디렉토리를 루트 폴더에 생성하고 하위에 파일을 두 개 생성했다.

- 00-makeFiles.config
- 00-set-timezone.config

`00-makeFiles.config`는 `appstart` 라는 이름의 스크립트 파일을 만든다. 여기에서 해당 스크립트 파일의 실행 권한을 명시하고, jar 파일을 실행하는 스크립트를 구성했다.

```text
files:
  "/sbin/appstart":
    mode: "000755"
    owner: webapp
    group: webapp
    content: |
      #!/usr/bin/env bash
      JAR_PATH=/var/app/current/application.jar

      # run application
      killall java
      java -Dfile.encoding=UTF-8 -DSpring.profiles.active=prod -jar $JAR_PATH
```

webapp이라는 사용자가 content 내의 스크립트를 만든다. 스크립트 내용은 `$JAR_PATH`에 위치하는 jar 파일을 prod 모드로 실행하는 것이다. 기존에 java 애플리케이션이 있다면 제거한다.

`00-set-timezone.config`는 EC2 기본 timezone이 UTC라 이를 Asia/Seoul로 변경하는 역할을 하도록 작성해두었다.

```text
commands:
  set_time_zone:
    command: ln -f -s /usr/share/zoneinfo/Asia/Seoul /etc/localtime
```


다음으로 서버 구동 시 뜨는 nginx를 Reverst Proxy로 사용할 수 있도록 `.platform/nginx` 디렉토리 내에 `nginx.conf` 파일을 작성했다.

```nginx
user                    nginx;
error_log               /var/log/nginx/error.log warn;
pid                     /var/run/nginx.pid;
worker_processes        auto;
worker_rlimit_nofile     33282;

events {
    use epoll;
    worker_connections  1024;
}

http {
  include       /etc/nginx/mime.types;

  default_type  application/octet-stream;

  log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

  include       conf.d/*.conf;

  map $http_upgrade $connection_upgrade {
      default     "upgrade";
  }

  upstream asker {
    server 127.0.0.1:8080;
    keepalive 1024;
  }

  server {
      listen        80 default_server;

      location / {
          proxy_pass          http://asker;
          proxy_http_version  1.1;
          proxy_set_header    Connection          $connection_upgrade;
          proxy_set_header    Upgrade             $http_upgrade;

          proxy_set_header    Host                $host;
          proxy_set_header    X-Real-IP           $remote_addr;
          proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;
      }

      access_log    /var/log/nginx/access.log main;

      client_header_timeout 60;
      client_body_timeout   60;
      keepalive_timeout     60;
      gzip                  off;
      gzip_comp_level       4;

      # Include the Elastic Beanstalk generated locations
      include conf.d/elasticbeanstalk/healthd.conf;
  }
}
```

아직은 nginx 설정에 대해 잘 몰라서 우선은 EB에서 5000번 포트로 요청이 오면, 이를 애플리케이션 구동 포트인 8080 포트로 포워딩 되도록 설정해두었다. 만약 굳이 애플리케이션 서버를 타지 않고 static한 자원을 요청한 경우에는 nginx 단에서 미리 준비한 자원을 반환하도록 설정할 수도 있을 것 같다. Reverse Proxy로 또 어떤 것을 할 수 있는지는 앞으로 좀 더 공부가 필요하다.

Github Action 트리거를 위해 `.github/workflows` 경로에 `eb-deploy.yml` 파일을 생성했다. 이 파일에 명시한 작업은 다음과 같다.

- main 브랜치에 push 이벤트가 일어나면 다음 스텝을 차례로 수행하도록 명시
- JDK 17 세팅
- Gradle Build
- 배포를 위한 패키지를 생성(jar 파일과 Procfile 파일, .ebextensions 디렉토리와 .platform 디렉토리 하위의 모든 파일을 zip으로 패키징)
- AWS EB에 배포

```yml
name: Deploy to EC2

on:
  push:
    branches: [ "main" ]

env:
  AWS_REGION: ap-northeast-2
  EB_APPLICATION_NAME: asker-server
  EB_ENVIRONMENT_NAME: asker-server-env

permissions:
  contents: read

jobs:
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    environment: develop

    steps:
      # 기본 체크아웃
      - name: Checkout
        uses: actions/checkout@v3

      # JDK 17 세팅
      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '17'

      # Gradle build (Test 제외)
      - name: Build with Gradle
        uses: gradle/gradle-build-action@v2
        with:
          arguments: clean build -x test

      - name: Get current time
        uses: josStorer/get-current-time@v2.1.1
        id: current-time
        with:
          format: YYYY-MM-DDTHH-mm-ss
          utcOffset: "+09:00"

      # JAR(application.jar) to ZIP for Beanstalk
      # ZIP File encludes Procfile, .ebextensions, .playform
      - name: Generate Deployment Package
        run: |
          mkdir -p deploy
          cp build/libs/*.jar deploy/application.jar
          cp Procfile deploy/Procfile
          cp -r .ebextensions deploy/.ebextensions
          cp -r .platform deploy/.platform
          cd deploy && zip -r deploy.zip .

      # Beanstalk Deploy
      - name: Beanstalk Deploy
        uses: einaregilsson/beanstalk-deploy@v21
        with:
          aws_access_key: ${{ secrets.AWS_EB_ACCESS_KEY }}
          aws_secret_key: ${{ secrets.AWS_EB_ACCESS_SECRET }}
          application_name: ${{ env.EB_APPLICATION_NAME }} # EB Application Name
          environment_name: ${{ env.EB_ENVIRONMENT_NAME }} # EB Environment Name
          version_label: version-${{ steps.current-time.outputs.formattedTime }} # 배포 버전은 타임스탬프를 이용하여 구분
          region: ${{ env.AWS_REGION }}
          deployment_package: deploy/deploy.zip
          wait_for_environment_recovery: 300
```

배포될 파일의 버전은 타임스탬프를 이용해 시간대로 구분하도록 설정해 두었다.

EB의 경우 기본적으로 `/` 경로로 health check 요청을 보낸다. 여기에서 200을 반환해야 서비스가 정상 구동되고 있는 것으로 판단하기 때문에 프로젝트 Security 설정에서 `/` 경로와 정확히 일치하는 요청은 인가 절차를 밟지 않도록 수정하고, 해당 경로로 들어온 요청의 반환 값으로 `Asker Server is Up and Running…` String을 반환하도록 처리해 두었다.

```java
// SecurityConfig.class

@Bean
public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
	// ...

	http
  	.authorizeHttpRequests(request -> {
   	request.requestMatchers("/").permitAll();        // for EB Health Check
   	request.requestMatchers("/api/**").permitAll();
   	request.anyRequest().authenticated();
  	});

	// ...
}
```


최종적으로 health check에 통과했고 서버 애플리케이션도 EC2에서 정상적으로 구동되었다.





---

아쉬운 부분은 현재 구성대로라면 Github Action에서 프로젝트를 빌드하고, 빌드된 jar 파일과 EB 구동을 위한 설정 파일들을 zip 으로 패키징해 S3 버킷에 업로드 하는데, 각 패키징의 파일 사이즈가 꽤 크다. 또 EB를 사용하기 때문에 배포 수행 시 EC2를 프로비저닝 해주긴 하지만 만약 서버 애플리케이션을 Docker Image로 빌드하고, Image를 EC2에서 구동시킬 수 있다면 저장 공간을 덜 쓸 수 있을 것 같다는 생각이 들었다.

